{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Assignment_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreya0202/SentimentAnalysis/blob/master/NLP_Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUR80o6TQTZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import pandas library for reading the dataset\n",
        "import pandas as pd\n",
        "\n",
        "#import sklearn model selection package to split data into train and test models\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#import numpy library for data manipulation\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TU2j6jQ9R7aA",
        "colab_type": "code",
        "outputId": "7634e11a-5793-4146-fde4-19b81705e13d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "#Import Natural Language Toolkit\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords') #For stop words removal\n",
        "nltk.download('wordnet') #For lemmatizing\n",
        "nltk.download('tagsets') #Help with any nltk tag\n",
        "nltk.download('averaged_perceptron_tagger') #For POS tagging"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Unzipping help/tagsets.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJts0n5-R_JP",
        "colab_type": "code",
        "outputId": "c0c49e6b-681e-438e-8251-80f2ae4cddd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "#reading CSV file and storing in a variable\n",
        "dataset = pd.read_csv('/content/drive/My Drive/rotten_tomato.csv')\n",
        "\n",
        "#removing null values\n",
        "dataset = dataset.dropna()\n",
        "\n",
        "print(\"Here are the first 10 rows of the dataset: \")\n",
        "#printing first 10 records of dataset\n",
        "dataset.head(10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Here are the first 10 rows of the dataset: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>of escapades demonstrating the adage that what...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>of</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>escapades demonstrating the adage that what is...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>escapades</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>demonstrating the adage that what is good for ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0         1  ...          1\n",
              "1         2  ...          2\n",
              "2         3  ...          2\n",
              "3         4  ...          2\n",
              "4         5  ...          2\n",
              "5         6  ...          2\n",
              "6         7  ...          2\n",
              "7         8  ...          2\n",
              "8         9  ...          2\n",
              "9        10  ...          2\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "504uPkClbTp-",
        "colab_type": "code",
        "outputId": "b9e622db-4ece-4dd0-908c-3ffc5cd90eaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "dataset.groupby('Sentiment')['PhraseId'].nunique()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment\n",
              "0     7072\n",
              "1    27273\n",
              "2    79582\n",
              "3    32927\n",
              "4     9206\n",
              "Name: PhraseId, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CsIjMmmS4IW",
        "colab_type": "code",
        "outputId": "4304eacc-795b-4dc5-ccdb-d22d5f148bd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dataset.groupby('Sentiment')['PhraseId'].nunique().plot(kind='bar')\n",
        "plt.title('Data Visualization')\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAETCAYAAADUAmpRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0xeDxpfixAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfQ-5ztVVA78",
        "colab_type": "code",
        "outputId": "bab4e8c1-2b89-44b6-b7a8-b9a64a07de0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer,LancasterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "X = dataset['Phrase']\n",
        "Y = dataset['Sentiment']\n",
        "\n",
        "stopwords_en = set(stopwords.words('english'))\n",
        "porter = PorterStemmer()\n",
        "lancaster = LancasterStemmer()\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "punctuations = \"?:!.,;()-/\\\"\"\n",
        "\n",
        "remove_punctuations = True\n",
        "remove_stopwords = True\n",
        "useLemma = True\n",
        "useStem = False\n",
        "\n",
        "\n",
        "X = X.values\n",
        "Y = Y.values\n",
        "\n",
        "reviews = X\n",
        "\n",
        "for review in range(len(X)):\n",
        "    tmp_review = []\n",
        "    for word in word_tokenize(X[review]):\n",
        "        new_word = word\n",
        "        if remove_stopwords and (word in stopwords_en):\n",
        "            continue\n",
        "        if remove_punctuations and (word in punctuations):\n",
        "            continue\n",
        "        if useStem:\n",
        "            new_word = lancaster.stem(new_word)\n",
        "        if useLemma:\n",
        "            new_word = wordnet_lemmatizer.lemmatize(new_word)\n",
        "\n",
        "        tmp_review.append(new_word)\n",
        "\n",
        "    reviews[review] = ' '.join(tmp_review)\n",
        "\n",
        "    if(review % 10000 == 0):\n",
        "        print(str(review) + \" records processed.\")\n",
        "\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, stratify=Y, random_state=2003)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 records processed.\n",
            "10000 records processed.\n",
            "20000 records processed.\n",
            "30000 records processed.\n",
            "40000 records processed.\n",
            "50000 records processed.\n",
            "60000 records processed.\n",
            "70000 records processed.\n",
            "80000 records processed.\n",
            "90000 records processed.\n",
            "100000 records processed.\n",
            "110000 records processed.\n",
            "120000 records processed.\n",
            "130000 records processed.\n",
            "140000 records processed.\n",
            "150000 records processed.\n",
            "(109242,)\n",
            "(109242,)\n",
            "(46818,)\n",
            "(46818,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N314Xkv2VH20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for one hot encoding\n",
        "from sklearn.preprocessing import LabelBinarizer \n",
        "import numpy as np\n",
        "from itertools import chain"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6bBumGuZfrM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# new_df = pd.DataFrame(y_train, columns=['Sentiment'])\n",
        "\n",
        "# # new_df.index.name = 'Id'\n",
        "\n",
        "# new_df.groupby('Sentiment')[new_df.index.name].nunique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gcms6zm3aKxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#vectorizer = TfidfVectorizer(stop_words=\"english\", ngram_range=(1, 1))\n",
        "#bigram_vectorizer = TfidfVectorizer(stop_words=\"english\", ngram_range=(1, 2))\n",
        "#trigram_vectorizer = TfidfVectorizer(stop_words=\"english\", ngram_range=(1, 3))\n",
        "vec_len = 1000 #<set_a_length_of_your_choice>\n",
        "count_vectorizer = CountVectorizer(max_features=vec_len)\n",
        "encoder = LabelBinarizer()\n",
        "\n",
        "#count_vectorizer = CountVectorizer(stop_words=\"english\", ngram_range=(1, 1))\n",
        "X = count_vectorizer.fit_transform(dataset['Phrase'])\n",
        "Y = dataset['Sentiment']\n",
        "x_train = count_vectorizer.transform(x_train)\n",
        "y_train = encoder.fit_transform(y_train)\n",
        "x_test = count_vectorizer.transform(x_test)\n",
        "y_test = encoder.transform(y_test)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m79niFKbTQOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_np = x_train.toarray()\n",
        "y_train_np = np.array(y_train)\n",
        "\n",
        "x_test_np = x_test.toarray()\n",
        "y_test_np = np.array(y_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fh2gp3_JTrz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "torch.manual_seed(2020)\n",
        "\n",
        "from torch.nn import Conv1d, MaxPool1d, Flatten, Linear\n",
        "\n",
        "from torch.nn.functional import relu, softmax, sigmoid\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34Bq0Jfsm0U4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CnnRegressor(torch.nn.Module):\n",
        "  #defining initialization method\n",
        "  def __init__(self, batch_size, inputs, outputs):\n",
        "    #initializing super class and storing parameters\n",
        "    super(CnnRegressor, self).__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.inputs = inputs\n",
        "    self.outputs = outputs\n",
        "    #defining input layer with kernel size 1\n",
        "    self.input_layer = Conv1d(inputs, batch_size,1)\n",
        "    #defining max pooling layer with kernel size 1\n",
        "    self.max_pooling_layer = MaxPool1d(1)\n",
        "    #defining convolution layer with kernel size 1\n",
        "    self.conv_layer = Conv1d(batch_size, 128, 1)\n",
        "    #defining max pooling layer with kernel size 1\n",
        "    self.max_pooling_1 = MaxPool1d(1)\n",
        "    #defining convolution layer with kernel size 1\n",
        "    self.conv_layer_1 = Conv1d(128, 256, 1)\n",
        "    #defining flatten layer\n",
        "    self.flatten_layer = Flatten()\n",
        "    #defining sequential layer\n",
        "    self.linear_layer = Linear(256, 64)\n",
        "    #defining sequential output layer\n",
        "    self.output_layer = Linear(64, outputs)\n",
        "    self.softmax = torch.nn.Softmax()\n",
        "    #self.sigmoid = torch.nn.Sigmoid()\n",
        "    #tensor.sigmoid\n",
        "\n",
        "#method to feed inputs to the model\n",
        "  def feed(self, input):\n",
        "    #reshaping the input to be feed to the input layer\n",
        "    input = input.reshape((self.batch_size, self.inputs, 1))\n",
        "    #passing the input through relu function and getting output for first layer\n",
        "    output = relu(self.input_layer(input))\n",
        "    #passing output of the first layer as input in max pooling layer\n",
        "    output = self.max_pooling_layer(output)\n",
        "    #passing the input through relu function and getting output for second layer\n",
        "    output = relu(self.conv_layer(output))\n",
        "    #passing output of the second layer as input in max pooling layer\n",
        "    output = self.max_pooling_1(output)\n",
        "    #passing the input through relu function and getting output for third layer\n",
        "    output = relu(self.conv_layer_1(output))\n",
        "    #getting output for flatten layer\n",
        "    output = self.flatten_layer(output)\n",
        "    #getting output for linear layer\n",
        "    output = self.linear_layer(output)\n",
        "    #getting final output\n",
        "    output = self.output_layer(output)\n",
        "\n",
        "    #output = sigmoid(output)\n",
        "    output_softmax = self.softmax(output)\n",
        "    output_ = torch.round(output_softmax)\n",
        "    \n",
        "\n",
        "    return output_softmax, output_\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBHDryeKUGlM",
        "colab_type": "code",
        "outputId": "0393b4a2-4d50-4dcd-f41b-74ce76cf14ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#Stochastic gradient descent package\n",
        "from torch.optim import Rprop, Adam\n",
        "\n",
        "#mean absolute error loss\n",
        "#from torch.nn import L1Loss\n",
        "#Cross ENtropy Loss for CLassification Problems\n",
        "from torch.nn import CrossEntropyLoss\n",
        "!pip install pytorch-ignite\n",
        "# from ignite.contrib.metrics.regression.r2_score import R2Score\n",
        "from ignite.metrics import Accuracy, Recall, Precision"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-ignite in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pytorch-ignite) (1.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "if60cUKPVidT",
        "colab_type": "code",
        "outputId": "a9f2fdb3-eb05-4453-bbd3-40decf01dfc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "batch_size = 64\n",
        "model = CnnRegressor(batch_size, x_train.shape[1], 5)\n",
        "model.cuda()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CnnRegressor(\n",
              "  (input_layer): Conv1d(1000, 64, kernel_size=(1,), stride=(1,))\n",
              "  (max_pooling_layer): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv_layer): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
              "  (max_pooling_1): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv_layer_1): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
              "  (flatten_layer): Flatten()\n",
              "  (linear_layer): Linear(in_features=256, out_features=64, bias=True)\n",
              "  (output_layer): Linear(in_features=64, out_features=5, bias=True)\n",
              "  (softmax): Softmax(dim=None)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Co1TCVk8FGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#method to return MSE and R^2 scores\n",
        "def model_loss(model, dataset, train = False, optimizer = None):\n",
        "  #performance = L1Loss()\n",
        "  performance=CrossEntropyLoss().cuda()\n",
        "  accu = Accuracy()\n",
        "  prec = Precision()\n",
        "  rec = Recall()\n",
        "  avg_accu = 0\n",
        "  avg_rec = 0\n",
        "  avg_prec = 0\n",
        "  avg_loss = 0\n",
        "  count = 0\n",
        "  for input, output in iter(dataset):\n",
        "    #getting prediction for training dataset\n",
        "    #predictions, predictions_ = model.feed(input)\n",
        "    predictions, predictions_ = model.feed(input)\n",
        "    #tmp_op = output.toarray()\n",
        "    tmp_op = output.argmax(dim = 1).squeeze(0)\n",
        "    # labels = np.argmax(tmp_op, axis=1)\n",
        "    # op = torch.from_numpy(labels).cuda().float()\n",
        "    #Get the expected output \n",
        "    # expected=-1\n",
        "    # for index in range(len(tmp_op)):\n",
        "    #   if tmp_op[index]==1:\n",
        "    #     expected = index\n",
        "    #     break\n",
        "    # expected = torch.tensor(expected).unsqueeze(0).cuda()\n",
        "\n",
        "    #getting the MSE loss\n",
        "    #loss = performance(predictions, output)\n",
        "\n",
        "    #getting Cross Entropy Loss\n",
        "    loss = performance(predictions,tmp_op)\n",
        "\n",
        "    accu.update([predictions_, output])\n",
        "    tmp_accu = accu.compute()\n",
        "\n",
        "    prec.update([predictions_, output])\n",
        "    tmp_prec = prec.compute()\n",
        "\n",
        "    rec.update([predictions_, output])\n",
        "    tmp_rec = rec.compute()\n",
        "\n",
        "    if(train):\n",
        "      #clear errors\n",
        "      optimizer.zero_grad()\n",
        "      #compute gradients\n",
        "      loss.backward()\n",
        "      #update parameters based on gradients\n",
        "      optimizer.step()\n",
        "    \n",
        "    #storing the loss and updating counter\n",
        "    avg_loss += loss.item()\n",
        "    avg_accu += tmp_accu\n",
        "    avg_prec += tmp_prec.item()\n",
        "    avg_rec += tmp_rec.item()\n",
        "    count += 1\n",
        " #returning Average accuracy, Precision, Recall per count\n",
        "  return avg_loss/count, avg_accu / count, avg_prec / count, avg_rec / count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLLIVSeGbMbl",
        "colab_type": "code",
        "outputId": "d40fd3f9-f3bb-4899-f588-c9a729ddefe2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_train_np.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(109242, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMthpj3fHYWH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "# !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "# !pip install gputil\n",
        "# !pip install psutil\n",
        "# !pip install humanize\n",
        "\n",
        "# import psutil\n",
        "# import humanize\n",
        "# import os\n",
        "# import GPUtil as GPU\n",
        "\n",
        "# GPUs = GPU.getGPUs()\n",
        "# # XXX: only one GPU on Colab and isn’t guaranteed\n",
        "# gpu = GPUs[0]\n",
        "# def printm():\n",
        "#     process = psutil.Process(os.getpid())\n",
        "#     print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" |     Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n",
        "#     print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total     {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "# printm()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiEy6IJhVzKP",
        "colab_type": "code",
        "outputId": "651c1340-e129-41f8-c353-d07346bcd2ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Block to obtain training loss\n",
        "epochs = 100\n",
        "optimizer = Rprop(model.parameters(), lr=1e-5)\n",
        "optimizer_ = Adam(model.parameters(), lr=1e-5)\n",
        "inputs = torch.from_numpy(x_train_np).cuda().float()\n",
        "outputs = torch.from_numpy(y_train_np).cuda().float()\n",
        "print(inputs.size())\n",
        "print(outputs.size())\n",
        "tensor = TensorDataset(inputs, outputs)\n",
        "loader = DataLoader(tensor, batch_size, shuffle=True, drop_last=True)\n",
        "accuracies = []\n",
        "acc_adam = []\n",
        "for epoch in range(epochs):\n",
        "  avg_loss, avg_accu, avg_prec, avg_rec = model_loss(model, loader, train=True, optimizer=optimizer)\n",
        "  av_loss, av_accu, av_prec, av_rec = model_loss(model, loader, train=True, optimizer=optimizer_)\n",
        "  if epoch == 0:\n",
        "    accuracies = [avg_accu]\n",
        "    acc_adam = [av_accu]\n",
        "  else:\n",
        "    accuracies = [*accuracies, avg_accu]\n",
        "    acc_adam = [*acc_adam, av_accu]\n",
        "  f1 = (2*(avg_prec*avg_rec)/(avg_rec + avg_prec))\n",
        "  f1_adam = (2*(av_prec*av_rec)/(av_rec + av_prec))\n",
        "  print(\"Rprop: The Training Resulting Epoch : \" + str(epoch + 1) + \":\\n\\tAverage Loss = \" + str(avg_loss) + \"\\n\\tAccuracy = \" + str(avg_accu) + \"\\n\\tAverage Precision = \" + str(avg_prec) + \"\\n\\tAverage Recall = \" + str(avg_rec) +  \"\\n\\tF1 score = \" + str(f1))\n",
        "  print(\"Adam: The Training Resulting Epoch : \" + str(epoch + 1) + \":\\n\\tAverage Loss = \" + str(av_loss) + \"\\n\\tAccuracy = \" + str(av_accu) + \"\\n\\tAverage Precision = \" + str(av_prec) + \"\\n\\tAverage Recall = \" + str(av_rec) +  \"\\n\\tF1 score = \" + str(f1_adam))\n",
        "\n",
        "#saving the trained model in drive\n",
        "torch.save(model.state_dict(), '/content/drive/My Drive/110534_sentiment_analysis.pth')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([109242, 1000])\n",
            "torch.Size([109242, 5])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:51: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Rprop: The Training Resulting Epoch : 1:\n",
            "\tAverage Loss = 1.3991344511019805\n",
            "\tAccuracy = 0.8033076582436267\n",
            "\tAverage Precision = 0.4991736738931219\n",
            "\tAverage Recall = 0.46058146438985875\n",
            "\tF1 score = 0.4791016636136448\n",
            "Adam: The Training Resulting Epoch : 1:\n",
            "\tAverage Loss = 1.3948765486513743\n",
            "\tAccuracy = 0.8033190671740522\n",
            "\tAverage Precision = 0.508297667935128\n",
            "\tAverage Recall = 0.508297667935128\n",
            "\tF1 score = 0.508297667935128\n",
            "Rprop: The Training Resulting Epoch : 2:\n",
            "\tAverage Loss = 1.3948673894508783\n",
            "\tAccuracy = 0.8041643262115473\n",
            "\tAverage Precision = 0.5104108155288729\n",
            "\tAverage Recall = 0.5104108155288729\n",
            "\tF1 score = 0.5104108155288729\n",
            "Adam: The Training Resulting Epoch : 2:\n",
            "\tAverage Loss = 1.3949040245059507\n",
            "\tAccuracy = 0.8036001845239841\n",
            "\tAverage Precision = 0.5090004613099641\n",
            "\tAverage Recall = 0.5090004613099641\n",
            "\tF1 score = 0.5090004613099641\n",
            "Rprop: The Training Resulting Epoch : 3:\n",
            "\tAverage Loss = 1.3948581772141273\n",
            "\tAccuracy = 0.803139230263754\n",
            "\tAverage Precision = 0.5078480756593892\n",
            "\tAverage Recall = 0.5078480756593892\n",
            "\tF1 score = 0.5078480756593892\n",
            "Adam: The Training Resulting Epoch : 3:\n",
            "\tAverage Loss = 1.3860548335670166\n",
            "\tAccuracy = 0.8050165812320587\n",
            "\tAverage Precision = 0.5126440616632476\n",
            "\tAverage Recall = 0.5094627258710768\n",
            "\tF1 score = 0.5110484427691129\n",
            "Rprop: The Training Resulting Epoch : 4:\n",
            "\tAverage Loss = 1.374910306469357\n",
            "\tAccuracy = 0.8169273843670609\n",
            "\tAverage Precision = 0.5471427179674149\n",
            "\tAverage Recall = 0.4913680927073682\n",
            "\tF1 score = 0.5177576795598056\n",
            "Adam: The Training Resulting Epoch : 4:\n",
            "\tAverage Loss = 1.3702035110273507\n",
            "\tAccuracy = 0.8147368525257773\n",
            "\tAverage Precision = 0.5392401732524282\n",
            "\tAverage Recall = 0.5066612247007152\n",
            "\tF1 score = 0.5224432955584233\n",
            "Rprop: The Training Resulting Epoch : 5:\n",
            "\tAverage Loss = 1.3657413126435676\n",
            "\tAccuracy = 0.8144191945076222\n",
            "\tAverage Precision = 0.5369249563187463\n",
            "\tAverage Recall = 0.5241551951936428\n",
            "\tF1 score = 0.530463235755484\n",
            "Adam: The Training Resulting Epoch : 5:\n",
            "\tAverage Loss = 1.3630171917108131\n",
            "\tAccuracy = 0.8152382794275085\n",
            "\tAverage Precision = 0.5388117695017204\n",
            "\tAverage Recall = 0.5288863756583365\n",
            "\tF1 score = 0.533802939015316\n",
            "Rprop: The Training Resulting Epoch : 6:\n",
            "\tAverage Loss = 1.3596088511024242\n",
            "\tAccuracy = 0.8155907132492031\n",
            "\tAverage Precision = 0.539479771513468\n",
            "\tAverage Recall = 0.5326059666385345\n",
            "\tF1 score = 0.5360208329683575\n",
            "Adam: The Training Resulting Epoch : 6:\n",
            "\tAverage Loss = 1.3574676240454804\n",
            "\tAccuracy = 0.8179221821779848\n",
            "\tAverage Precision = 0.5453654708107876\n",
            "\tAverage Recall = 0.538647693230706\n",
            "\tF1 score = 0.5419857665283191\n",
            "Rprop: The Training Resulting Epoch : 7:\n",
            "\tAverage Loss = 1.3543401179531673\n",
            "\tAccuracy = 0.8186194782170062\n",
            "\tAverage Precision = 0.5469595216605616\n",
            "\tAverage Recall = 0.5421711153057811\n",
            "\tF1 score = 0.5445547922732566\n",
            "Adam: The Training Resulting Epoch : 7:\n",
            "\tAverage Loss = 1.3526861584480034\n",
            "\tAccuracy = 0.8188374224549151\n",
            "\tAverage Precision = 0.5474723171598133\n",
            "\tAverage Recall = 0.5430895017432517\n",
            "\tF1 score = 0.5452721024904584\n",
            "Rprop: The Training Resulting Epoch : 8:\n",
            "\tAverage Loss = 1.3499187695742492\n",
            "\tAccuracy = 0.8204649571130683\n",
            "\tAverage Precision = 0.5514391134012172\n",
            "\tAverage Recall = 0.5484766126319478\n",
            "\tF1 score = 0.5499538734332898\n",
            "Adam: The Training Resulting Epoch : 8:\n",
            "\tAverage Loss = 1.3485185002246467\n",
            "\tAccuracy = 0.8206068137628477\n",
            "\tAverage Precision = 0.5517664873507128\n",
            "\tAverage Recall = 0.5491039764204153\n",
            "\tF1 score = 0.5504320121768483\n",
            "Rprop: The Training Resulting Epoch : 9:\n",
            "\tAverage Loss = 1.3460118765009246\n",
            "\tAccuracy = 0.8225739294218729\n",
            "\tAverage Precision = 0.5566481343643354\n",
            "\tAverage Recall = 0.5545534320130807\n",
            "\tF1 score = 0.5555988088493653\n",
            "Adam: The Training Resulting Epoch : 9:\n",
            "\tAverage Loss = 1.3451447140988824\n",
            "\tAccuracy = 0.8224157279713082\n",
            "\tAverage Precision = 0.5562427639864239\n",
            "\tAverage Recall = 0.5542297063648163\n",
            "\tF1 score = 0.5552344105464212\n",
            "Rprop: The Training Resulting Epoch : 10:\n",
            "\tAverage Loss = 1.3429277989956587\n",
            "\tAccuracy = 0.8222403351434153\n",
            "\tAverage Precision = 0.5557588718430388\n",
            "\tAverage Recall = 0.554177636794977\n",
            "\tF1 score = 0.5549671279913946\n",
            "Adam: The Training Resulting Epoch : 10:\n",
            "\tAverage Loss = 1.342320555749001\n",
            "\tAccuracy = 0.8237998527935692\n",
            "\tAverage Precision = 0.5596660356523762\n",
            "\tAverage Recall = 0.5581068467833432\n",
            "\tF1 score = 0.5588853537563693\n",
            "Rprop: The Training Resulting Epoch : 11:\n",
            "\tAverage Loss = 1.3403538182500099\n",
            "\tAccuracy = 0.8240230957022938\n",
            "\tAverage Precision = 0.5601767894516523\n",
            "\tAverage Recall = 0.5590740416090114\n",
            "\tF1 score = 0.5596248722862391\n",
            "Adam: The Training Resulting Epoch : 11:\n",
            "\tAverage Loss = 1.3400593697675367\n",
            "\tAccuracy = 0.8245974342840289\n",
            "\tAverage Precision = 0.5616613764450418\n",
            "\tAverage Recall = 0.5601320732376363\n",
            "\tF1 score = 0.5608956824175751\n",
            "Rprop: The Training Resulting Epoch : 12:\n",
            "\tAverage Loss = 1.3383361655271067\n",
            "\tAccuracy = 0.8255519283326868\n",
            "\tAverage Precision = 0.5640095961989913\n",
            "\tAverage Recall = 0.5628646804098808\n",
            "\tF1 score = 0.5634365566813608\n",
            "Adam: The Training Resulting Epoch : 12:\n",
            "\tAverage Loss = 1.3381942753076275\n",
            "\tAccuracy = 0.8246871849729814\n",
            "\tAverage Precision = 0.5618181545925063\n",
            "\tAverage Recall = 0.5609128286455679\n",
            "\tF1 score = 0.5613651266094833\n",
            "Rprop: The Training Resulting Epoch : 13:\n",
            "\tAverage Loss = 1.3365106866340146\n",
            "\tAccuracy = 0.8257243868200645\n",
            "\tAverage Precision = 0.5643862833394716\n",
            "\tAverage Recall = 0.5637269557196961\n",
            "\tF1 score = 0.5640564268570333\n",
            "Adam: The Training Resulting Epoch : 13:\n",
            "\tAverage Loss = 1.3365626046554144\n",
            "\tAccuracy = 0.8270699922228115\n",
            "\tAverage Precision = 0.5677926359379585\n",
            "\tAverage Recall = 0.5668101831697013\n",
            "\tF1 score = 0.5673009842008229\n",
            "Rprop: The Training Resulting Epoch : 14:\n",
            "\tAverage Loss = 1.3349488578116628\n",
            "\tAccuracy = 0.8269743895000232\n",
            "\tAverage Precision = 0.567533826297902\n",
            "\tAverage Recall = 0.5667122386810646\n",
            "\tF1 score = 0.5671227349322631\n",
            "Adam: The Training Resulting Epoch : 14:\n",
            "\tAverage Loss = 1.334981234873026\n",
            "\tAccuracy = 0.82568699714883\n",
            "\tAverage Precision = 0.564322956506402\n",
            "\tAverage Recall = 0.563388812777453\n",
            "\tF1 score = 0.5638554977414224\n",
            "Rprop: The Training Resulting Epoch : 15:\n",
            "\tAverage Loss = 1.3333088249003062\n",
            "\tAccuracy = 0.827465491838709\n",
            "\tAverage Precision = 0.5687414654382432\n",
            "\tAverage Recall = 0.5680981382889011\n",
            "\tF1 score = 0.5684196198370929\n",
            "Adam: The Training Resulting Epoch : 15:\n",
            "\tAverage Loss = 1.3333849610645074\n",
            "\tAccuracy = 0.8278803015081073\n",
            "\tAverage Precision = 0.5698043985852332\n",
            "\tAverage Recall = 0.568960688989673\n",
            "\tF1 score = 0.5693822312357735\n",
            "Rprop: The Training Resulting Epoch : 16:\n",
            "\tAverage Loss = 1.3317461022877888\n",
            "\tAccuracy = 0.8282527424858763\n",
            "\tAverage Precision = 0.5707432553509878\n",
            "\tAverage Recall = 0.5698476675901053\n",
            "\tF1 score = 0.5702951098644531\n",
            "Adam: The Training Resulting Epoch : 16:\n",
            "\tAverage Loss = 1.3317119969712332\n",
            "\tAccuracy = 0.8273503974999462\n",
            "\tAverage Precision = 0.5684848126459534\n",
            "\tAverage Recall = 0.5675806361205878\n",
            "\tF1 score = 0.5680323645733716\n",
            "Rprop: The Training Resulting Epoch : 17:\n",
            "\tAverage Loss = 1.330053191252079\n",
            "\tAccuracy = 0.8300594094721799\n",
            "\tAverage Precision = 0.5752874437239572\n",
            "\tAverage Recall = 0.5742240661843763\n",
            "\tF1 score = 0.5747552631053328\n",
            "Adam: The Training Resulting Epoch : 17:\n",
            "\tAverage Loss = 1.3302780836995294\n",
            "\tAccuracy = 0.8288040396358304\n",
            "\tAverage Precision = 0.5721602350500045\n",
            "\tAverage Recall = 0.5709739707849976\n",
            "\tF1 score = 0.5715664874066978\n",
            "Rprop: The Training Resulting Epoch : 18:\n",
            "\tAverage Loss = 1.328748915427455\n",
            "\tAccuracy = 0.8298551823493053\n",
            "\tAverage Precision = 0.5747981908417569\n",
            "\tAverage Recall = 0.5735679471748018\n",
            "\tF1 score = 0.5741824100287823\n",
            "Adam: The Training Resulting Epoch : 18:\n",
            "\tAverage Loss = 1.329084807725193\n",
            "\tAccuracy = 0.8311720920298594\n",
            "\tAverage Precision = 0.5780884350980267\n",
            "\tAverage Recall = 0.5769225523105873\n",
            "\tF1 score = 0.5775049052758466\n",
            "Rprop: The Training Resulting Epoch : 19:\n",
            "\tAverage Loss = 1.3276008938429364\n",
            "\tAccuracy = 0.8300929150888019\n",
            "\tAverage Precision = 0.5754070523032051\n",
            "\tAverage Recall = 0.5740719421742635\n",
            "\tF1 score = 0.5747387218791735\n",
            "Adam: The Training Resulting Epoch : 19:\n",
            "\tAverage Loss = 1.32797936901258\n",
            "\tAccuracy = 0.8298873702524239\n",
            "\tAverage Precision = 0.5749144712072911\n",
            "\tAverage Recall = 0.5734093061434915\n",
            "\tF1 score = 0.5741609022280522\n",
            "Rprop: The Training Resulting Epoch : 20:\n",
            "\tAverage Loss = 1.3265284250238156\n",
            "\tAccuracy = 0.8303362932783006\n",
            "\tAverage Precision = 0.5760609453628627\n",
            "\tAverage Recall = 0.574392423096244\n",
            "\tF1 score = 0.5752254742863124\n",
            "Adam: The Training Resulting Epoch : 20:\n",
            "\tAverage Loss = 1.3269437003666742\n",
            "\tAccuracy = 0.8310841518799135\n",
            "\tAverage Precision = 0.5779306036947917\n",
            "\tAverage Recall = 0.5762948404619508\n",
            "\tF1 score = 0.5771115629801348\n",
            "Rprop: The Training Resulting Epoch : 21:\n",
            "\tAverage Loss = 1.3254758795288775\n",
            "\tAccuracy = 0.8312920415777446\n",
            "\tAverage Precision = 0.5784359569928391\n",
            "\tAverage Recall = 0.5769223378766996\n",
            "\tF1 score = 0.5776781559489078\n",
            "Adam: The Training Resulting Epoch : 21:\n",
            "\tAverage Loss = 1.3259735313557517\n",
            "\tAccuracy = 0.8305142565803973\n",
            "\tAverage Precision = 0.5765073600098597\n",
            "\tAverage Recall = 0.5748305571698237\n",
            "\tF1 score = 0.5756677375461662\n",
            "Rprop: The Training Resulting Epoch : 22:\n",
            "\tAverage Loss = 1.3244302071552343\n",
            "\tAccuracy = 0.8304779657598251\n",
            "\tAverage Precision = 0.576479039805136\n",
            "\tAverage Recall = 0.5743271996272067\n",
            "\tF1 score = 0.5754011079021959\n",
            "Adam: The Training Resulting Epoch : 22:\n",
            "\tAverage Loss = 1.3249582681817997\n",
            "\tAccuracy = 0.8318401771214573\n",
            "\tAverage Precision = 0.5798867438161704\n",
            "\tAverage Recall = 0.5778090474256173\n",
            "\tF1 score = 0.5788460312182054\n",
            "Rprop: The Training Resulting Epoch : 23:\n",
            "\tAverage Loss = 1.3234584533455502\n",
            "\tAccuracy = 0.832821071701582\n",
            "\tAverage Precision = 0.5823624327808801\n",
            "\tAverage Recall = 0.5801702934278793\n",
            "\tF1 score = 0.5812642962916205\n",
            "Adam: The Training Resulting Epoch : 23:\n",
            "\tAverage Loss = 1.323913473806236\n",
            "\tAccuracy = 0.8330524649792203\n",
            "\tAverage Precision = 0.5829465911861438\n",
            "\tAverage Recall = 0.5807279308941526\n",
            "\tF1 score = 0.5818351459927712\n",
            "Rprop: The Training Resulting Epoch : 24:\n",
            "\tAverage Loss = 1.322383994234405\n",
            "\tAccuracy = 0.8337009197179291\n",
            "\tAverage Precision = 0.5847044119075566\n",
            "\tAverage Recall = 0.5815826525562505\n",
            "\tF1 score = 0.5831393542804607\n",
            "Adam: The Training Resulting Epoch : 24:\n",
            "\tAverage Loss = 1.3228721443961122\n",
            "\tAccuracy = 0.83276171146117\n",
            "\tAverage Precision = 0.582394205865715\n",
            "\tAverage Recall = 0.5789259424430206\n",
            "\tF1 score = 0.5806548951986825\n",
            "Rprop: The Training Resulting Epoch : 25:\n",
            "\tAverage Loss = 1.3213772631893403\n",
            "\tAccuracy = 0.8338454796257461\n",
            "\tAverage Precision = 0.5852312703303999\n",
            "\tAverage Recall = 0.5809957711736352\n",
            "\tF1 score = 0.5831058295167484\n",
            "Adam: The Training Resulting Epoch : 25:\n",
            "\tAverage Loss = 1.321855939706353\n",
            "\tAccuracy = 0.8336891504736905\n",
            "\tAverage Precision = 0.5848929973957502\n",
            "\tAverage Recall = 0.5802635169122682\n",
            "\tF1 score = 0.5825690600679165\n",
            "Rprop: The Training Resulting Epoch : 26:\n",
            "\tAverage Loss = 1.3201975198451688\n",
            "\tAccuracy = 0.8343366287407123\n",
            "\tAverage Precision = 0.5868040297366928\n",
            "\tAverage Recall = 0.5802947078234195\n",
            "\tF1 score = 0.5835312163862582\n",
            "Adam: The Training Resulting Epoch : 26:\n",
            "\tAverage Loss = 1.3206712985094657\n",
            "\tAccuracy = 0.8348169743852251\n",
            "\tAverage Precision = 0.5880592681177956\n",
            "\tAverage Recall = 0.5812855800320353\n",
            "\tF1 score = 0.5846528050333831\n",
            "Rprop: The Training Resulting Epoch : 27:\n",
            "\tAverage Loss = 1.3189832385791005\n",
            "\tAccuracy = 0.8352056801592046\n",
            "\tAverage Precision = 0.5892842991497209\n",
            "\tAverage Recall = 0.5808928714559057\n",
            "\tF1 score = 0.585058497526146\n",
            "Adam: The Training Resulting Epoch : 27:\n",
            "\tAverage Loss = 1.3193309506945146\n",
            "\tAccuracy = 0.8351609999717255\n",
            "\tAverage Precision = 0.5893597984128615\n",
            "\tAverage Recall = 0.5797452324012152\n",
            "\tF1 score = 0.5845129809438567\n",
            "Rprop: The Training Resulting Epoch : 28:\n",
            "\tAverage Loss = 1.3175032991317623\n",
            "\tAccuracy = 0.8355510488840101\n",
            "\tAverage Precision = 0.5908332581149345\n",
            "\tAverage Recall = 0.5781138436296266\n",
            "\tF1 score = 0.5844043503478908\n",
            "Adam: The Training Resulting Epoch : 28:\n",
            "\tAverage Loss = 1.3178410459515078\n",
            "\tAccuracy = 0.8362303144262179\n",
            "\tAverage Precision = 0.5926079285476075\n",
            "\tAverage Recall = 0.5796051616855744\n",
            "\tF1 score = 0.5860344285588263\n",
            "Rprop: The Training Resulting Epoch : 29:\n",
            "\tAverage Loss = 1.3159555366561952\n",
            "\tAccuracy = 0.8373874784564256\n",
            "\tAverage Precision = 0.5958771281131451\n",
            "\tAverage Recall = 0.5809133648276007\n",
            "\tF1 score = 0.588300108800155\n",
            "Adam: The Training Resulting Epoch : 29:\n",
            "\tAverage Loss = 1.3161469233972387\n",
            "\tAccuracy = 0.8373569059678179\n",
            "\tAverage Precision = 0.59563483364868\n",
            "\tAverage Recall = 0.5816702872673357\n",
            "\tF1 score = 0.5885697405703796\n",
            "Rprop: The Training Resulting Epoch : 30:\n",
            "\tAverage Loss = 1.3142208176788384\n",
            "\tAccuracy = 0.8376499657477471\n",
            "\tAverage Precision = 0.596487029171112\n",
            "\tAverage Recall = 0.5818790541817844\n",
            "\tF1 score = 0.5890924955650557\n",
            "Adam: The Training Resulting Epoch : 30:\n",
            "\tAverage Loss = 1.3144844165999892\n",
            "\tAccuracy = 0.8384531307271714\n",
            "\tAverage Precision = 0.5984459655321063\n",
            "\tAverage Recall = 0.5843867450278161\n",
            "\tF1 score = 0.5913328009111043\n",
            "Rprop: The Training Resulting Epoch : 31:\n",
            "\tAverage Loss = 1.3124264932880647\n",
            "\tAccuracy = 0.8388270724018446\n",
            "\tAverage Precision = 0.5993357054014363\n",
            "\tAverage Recall = 0.5856499189914569\n",
            "\tF1 score = 0.592413781385522\n",
            "Adam: The Training Resulting Epoch : 31:\n",
            "\tAverage Loss = 1.3126500708696291\n",
            "\tAccuracy = 0.8396590513165079\n",
            "\tAverage Precision = 0.6013946049215753\n",
            "\tAverage Recall = 0.5880457876331101\n",
            "\tF1 score = 0.5946452909167561\n",
            "Rprop: The Training Resulting Epoch : 32:\n",
            "\tAverage Loss = 1.3105889218493614\n",
            "\tAccuracy = 0.8395782205131663\n",
            "\tAverage Precision = 0.6012253872776888\n",
            "\tAverage Recall = 0.5876753553326369\n",
            "\tF1 score = 0.5943731557062775\n",
            "Adam: The Training Resulting Epoch : 32:\n",
            "\tAverage Loss = 1.3108532521677185\n",
            "\tAccuracy = 0.8384296947039153\n",
            "\tAverage Precision = 0.5981488500557139\n",
            "\tAverage Recall = 0.5855001186122413\n",
            "\tF1 score = 0.5917569007803379\n",
            "Rprop: The Training Resulting Epoch : 33:\n",
            "\tAverage Loss = 1.308680717159687\n",
            "\tAccuracy = 0.8407041237343589\n",
            "\tAverage Precision = 0.6038532190400662\n",
            "\tAverage Recall = 0.5916749857354444\n",
            "\tF1 score = 0.5977020756761188\n",
            "Adam: The Training Resulting Epoch : 33:\n",
            "\tAverage Loss = 1.3090337787395625\n",
            "\tAccuracy = 0.8415243913513666\n",
            "\tAverage Precision = 0.6058274318679676\n",
            "\tAverage Recall = 0.5942761954072873\n",
            "\tF1 score = 0.5999962221617174\n",
            "Rprop: The Training Resulting Epoch : 34:\n",
            "\tAverage Loss = 1.3067014032204014\n",
            "\tAccuracy = 0.842261946198119\n",
            "\tAverage Precision = 0.6076887360966376\n",
            "\tAverage Recall = 0.5962078390909497\n",
            "\tF1 score = 0.6018935441055357\n",
            "Adam: The Training Resulting Epoch : 34:\n",
            "\tAverage Loss = 1.3072742239811217\n",
            "\tAccuracy = 0.8405837689850204\n",
            "\tAverage Precision = 0.6032524548071525\n",
            "\tAverage Recall = 0.592775228084713\n",
            "\tF1 score = 0.5979679510868033\n",
            "Rprop: The Training Resulting Epoch : 35:\n",
            "\tAverage Loss = 1.3050722496590608\n",
            "\tAccuracy = 0.8410839054145725\n",
            "\tAverage Precision = 0.6045154579044165\n",
            "\tAverage Recall = 0.5940670709532038\n",
            "\tF1 score = 0.5992457236390631\n",
            "Adam: The Training Resulting Epoch : 35:\n",
            "\tAverage Loss = 1.3054839462775558\n",
            "\tAccuracy = 0.8422356391641938\n",
            "\tAverage Precision = 0.6072761843644191\n",
            "\tAverage Recall = 0.5977234615857927\n",
            "\tF1 score = 0.6024619580210405\n",
            "Rprop: The Training Resulting Epoch : 36:\n",
            "\tAverage Loss = 1.303270895553781\n",
            "\tAccuracy = 0.842084918841218\n",
            "\tAverage Precision = 0.6068652223448566\n",
            "\tAverage Recall = 0.597482999565638\n",
            "\tF1 score = 0.6021375658337129\n",
            "Adam: The Training Resulting Epoch : 36:\n",
            "\tAverage Loss = 1.3038264387936833\n",
            "\tAccuracy = 0.8422268303840339\n",
            "\tAverage Precision = 0.6071754172229716\n",
            "\tAverage Recall = 0.5980658675986791\n",
            "\tF1 score = 0.6025862161530284\n",
            "Rprop: The Training Resulting Epoch : 37:\n",
            "\tAverage Loss = 1.3016913180334486\n",
            "\tAccuracy = 0.8423398282212486\n",
            "\tAverage Precision = 0.6074583748528867\n",
            "\tAverage Recall = 0.5983633397816105\n",
            "\tF1 score = 0.6028765571956204\n",
            "Adam: The Training Resulting Epoch : 37:\n",
            "\tAverage Loss = 1.3021601723618412\n",
            "\tAccuracy = 0.8424681317482835\n",
            "\tAverage Precision = 0.6076250252283949\n",
            "\tAverage Recall = 0.5994198063383496\n",
            "\tF1 score = 0.6034945271684372\n",
            "Rprop: The Training Resulting Epoch : 38:\n",
            "\tAverage Loss = 1.300039851441892\n",
            "\tAccuracy = 0.8445923303102839\n",
            "\tAverage Precision = 0.6130204761004683\n",
            "\tAverage Recall = 0.6046691536160906\n",
            "\tF1 score = 0.6088161767777965\n",
            "Adam: The Training Resulting Epoch : 38:\n",
            "\tAverage Loss = 1.3005695727338265\n",
            "\tAccuracy = 0.8430566690782667\n",
            "\tAverage Precision = 0.6091456654523312\n",
            "\tAverage Recall = 0.600767905851948\n",
            "\tF1 score = 0.6049277807473321\n",
            "Rprop: The Training Resulting Epoch : 39:\n",
            "\tAverage Loss = 1.2983908346501492\n",
            "\tAccuracy = 0.844186990618347\n",
            "\tAverage Precision = 0.611829150159528\n",
            "\tAverage Recall = 0.6043863227568521\n",
            "\tF1 score = 0.6080849626648205\n",
            "Adam: The Training Resulting Epoch : 39:\n",
            "\tAverage Loss = 1.2989970943852298\n",
            "\tAccuracy = 0.843692045987972\n",
            "\tAverage Precision = 0.610597431694048\n",
            "\tAverage Recall = 0.603049816106926\n",
            "\tF1 score = 0.6068001547659613\n",
            "Rprop: The Training Resulting Epoch : 40:\n",
            "\tAverage Loss = 1.2967616877270751\n",
            "\tAccuracy = 0.8452158092692743\n",
            "\tAverage Precision = 0.6142692168049854\n",
            "\tAverage Recall = 0.6076589047889187\n",
            "\tF1 score = 0.6109461807661314\n",
            "Adam: The Training Resulting Epoch : 40:\n",
            "\tAverage Loss = 1.2974335245901647\n",
            "\tAccuracy = 0.8444010318304899\n",
            "\tAverage Precision = 0.6123451283573086\n",
            "\tAverage Recall = 0.6050322829111769\n",
            "\tF1 score = 0.6086667413247263\n",
            "Rprop: The Training Resulting Epoch : 41:\n",
            "\tAverage Loss = 1.2951897126988259\n",
            "\tAccuracy = 0.8461474361259949\n",
            "\tAverage Precision = 0.6166463556207465\n",
            "\tAverage Recall = 0.6098786048155093\n",
            "\tF1 score = 0.6132438085838606\n",
            "Adam: The Training Resulting Epoch : 41:\n",
            "\tAverage Loss = 1.29586126649226\n",
            "\tAccuracy = 0.8454791097108673\n",
            "\tAverage Precision = 0.6149747672880093\n",
            "\tAverage Recall = 0.6081445488614321\n",
            "\tF1 score = 0.6115405872109306\n",
            "Rprop: The Training Resulting Epoch : 42:\n",
            "\tAverage Loss = 1.2936334753232153\n",
            "\tAccuracy = 0.8473175217356865\n",
            "\tAverage Precision = 0.619552391273101\n",
            "\tAverage Recall = 0.6130260217865925\n",
            "\tF1 score = 0.6162719283192992\n",
            "Adam: The Training Resulting Epoch : 42:\n",
            "\tAverage Loss = 1.2943459873601952\n",
            "\tAccuracy = 0.8452041629327997\n",
            "\tAverage Precision = 0.6141424237432701\n",
            "\tAverage Recall = 0.6080484121712457\n",
            "\tF1 score = 0.6110802251674133\n",
            "Rprop: The Training Resulting Epoch : 43:\n",
            "\tAverage Loss = 1.2921372310357804\n",
            "\tAccuracy = 0.846315101017422\n",
            "\tAverage Precision = 0.6169920404789043\n",
            "\tAverage Recall = 0.6106399798863958\n",
            "\tF1 score = 0.6137995766451154\n",
            "Adam: The Training Resulting Epoch : 43:\n",
            "\tAverage Loss = 1.2928964518718116\n",
            "\tAccuracy = 0.8470681412109103\n",
            "\tAverage Precision = 0.6188621458866508\n",
            "\tAverage Recall = 0.612654615840236\n",
            "\tF1 score = 0.6157427361599059\n",
            "Rprop: The Training Resulting Epoch : 44:\n",
            "\tAverage Loss = 1.2907738787627583\n",
            "\tAccuracy = 0.8471500285627749\n",
            "\tAverage Precision = 0.6189881141716232\n",
            "\tAverage Recall = 0.6132005746606345\n",
            "\tF1 score = 0.6160807524987971\n",
            "Adam: The Training Resulting Epoch : 44:\n",
            "\tAverage Loss = 1.291550942210771\n",
            "\tAccuracy = 0.8457418031111931\n",
            "\tAverage Precision = 0.615454407090133\n",
            "\tAverage Recall = 0.6095957745835981\n",
            "\tF1 score = 0.6125110817883548\n",
            "Rprop: The Training Resulting Epoch : 45:\n",
            "\tAverage Loss = 1.2893503763192145\n",
            "\tAccuracy = 0.8476519236849317\n",
            "\tAverage Precision = 0.6201451476942524\n",
            "\tAverage Recall = 0.6149055239925219\n",
            "\tF1 score = 0.6175142214587043\n",
            "Adam: The Training Resulting Epoch : 45:\n",
            "\tAverage Loss = 1.2901250124676427\n",
            "\tAccuracy = 0.8473197431477371\n",
            "\tAverage Precision = 0.6193543856120419\n",
            "\tAverage Recall = 0.6138855082462772\n",
            "\tF1 score = 0.6166078208943991\n",
            "Rprop: The Training Resulting Epoch : 46:\n",
            "\tAverage Loss = 1.2880368135598732\n",
            "\tAccuracy = 0.8487683420788793\n",
            "\tAverage Precision = 0.6230082580653332\n",
            "\tAverage Recall = 0.6175015291484737\n",
            "\tF1 score = 0.6202426711868644\n",
            "Adam: The Training Resulting Epoch : 46:\n",
            "\tAverage Loss = 1.288755926269719\n",
            "\tAccuracy = 0.8490622965735538\n",
            "\tAverage Precision = 0.6236115417254906\n",
            "\tAverage Recall = 0.6187855161814104\n",
            "\tF1 score = 0.6211891557331889\n",
            "Rprop: The Training Resulting Epoch : 47:\n",
            "\tAverage Loss = 1.2866946472791827\n",
            "\tAccuracy = 0.8489019331260214\n",
            "\tAverage Precision = 0.6232321449203856\n",
            "\tAverage Recall = 0.6182841976157748\n",
            "\tF1 score = 0.6207483114773991\n",
            "Adam: The Training Resulting Epoch : 47:\n",
            "\tAverage Loss = 1.2875923246040433\n",
            "\tAccuracy = 0.8478525137061416\n",
            "\tAverage Precision = 0.6205843789249129\n",
            "\tAverage Recall = 0.6156778302602566\n",
            "\tF1 score = 0.6181213678961057\n",
            "Rprop: The Training Resulting Epoch : 48:\n",
            "\tAverage Loss = 1.2854046396745187\n",
            "\tAccuracy = 0.8484795032682034\n",
            "\tAverage Precision = 0.6222315049168601\n",
            "\tAverage Recall = 0.6169628065813431\n",
            "\tF1 score = 0.6195859552529837\n",
            "Adam: The Training Resulting Epoch : 48:\n",
            "\tAverage Loss = 1.286250404917481\n",
            "\tAccuracy = 0.8496776914730833\n",
            "\tAverage Precision = 0.6251281047735567\n",
            "\tAverage Recall = 0.6204622081565387\n",
            "\tF1 score = 0.6227864173993153\n",
            "Rprop: The Training Resulting Epoch : 49:\n",
            "\tAverage Loss = 1.2840998835189121\n",
            "\tAccuracy = 0.8494768040903604\n",
            "\tAverage Precision = 0.6245970415617315\n",
            "\tAverage Recall = 0.620051750169386\n",
            "\tF1 score = 0.6223160964665723\n",
            "Adam: The Training Resulting Epoch : 49:\n",
            "\tAverage Loss = 1.2849603075914058\n",
            "\tAccuracy = 0.8495526232853883\n",
            "\tAverage Precision = 0.6247465717670082\n",
            "\tAverage Recall = 0.6204139933645966\n",
            "\tF1 score = 0.6225727448890807\n",
            "Rprop: The Training Resulting Epoch : 50:\n",
            "\tAverage Loss = 1.2828639800215942\n",
            "\tAccuracy = 0.849126010581078\n",
            "\tAverage Precision = 0.6238082570529428\n",
            "\tAverage Recall = 0.6188013981407885\n",
            "\tF1 score = 0.621294740504728\n",
            "Adam: The Training Resulting Epoch : 50:\n",
            "\tAverage Loss = 1.2837741620934722\n",
            "\tAccuracy = 0.8500337571381011\n",
            "\tAverage Precision = 0.6260296149944182\n",
            "\tAverage Recall = 0.6213315231125353\n",
            "\tF1 score = 0.6236717215486699\n",
            "Rprop: The Training Resulting Epoch : 51:\n",
            "\tAverage Loss = 1.2817321667078652\n",
            "\tAccuracy = 0.8512326230204027\n",
            "\tAverage Precision = 0.6290310687209264\n",
            "\tAverage Recall = 0.6244005240605467\n",
            "\tF1 score = 0.62670724309434\n",
            "Adam: The Training Resulting Epoch : 51:\n",
            "\tAverage Loss = 1.2826410766782683\n",
            "\tAccuracy = 0.8500290363663143\n",
            "\tAverage Precision = 0.6258968492597645\n",
            "\tAverage Recall = 0.6217995120429085\n",
            "\tF1 score = 0.6238414529839371\n",
            "Rprop: The Training Resulting Epoch : 52:\n",
            "\tAverage Loss = 1.2805607138596833\n",
            "\tAccuracy = 0.8519874996662072\n",
            "\tAverage Precision = 0.6308286068404705\n",
            "\tAverage Recall = 0.6266814492333547\n",
            "\tF1 score = 0.6287481895563235\n",
            "Adam: The Training Resulting Epoch : 52:\n",
            "\tAverage Loss = 1.281533524621134\n",
            "\tAccuracy = 0.8503522844696895\n",
            "\tAverage Precision = 0.6267382636034348\n",
            "\tAverage Recall = 0.6224932989016755\n",
            "\tF1 score = 0.6246085689286514\n",
            "Rprop: The Training Resulting Epoch : 53:\n",
            "\tAverage Loss = 1.2794668172755805\n",
            "\tAccuracy = 0.8513529765717076\n",
            "\tAverage Precision = 0.6292058997630069\n",
            "\tAverage Recall = 0.6252003265860198\n",
            "\tF1 score = 0.6271967178712459\n",
            "Adam: The Training Resulting Epoch : 53:\n",
            "\tAverage Loss = 1.2804940410683332\n",
            "\tAccuracy = 0.8508134140360515\n",
            "\tAverage Precision = 0.6278088602229676\n",
            "\tAverage Recall = 0.6240010339181241\n",
            "\tF1 score = 0.6258991556395803\n",
            "Rprop: The Training Resulting Epoch : 54:\n",
            "\tAverage Loss = 1.2784069970791672\n",
            "\tAccuracy = 0.8516719850534079\n",
            "\tAverage Precision = 0.6299382203373668\n",
            "\tAverage Recall = 0.6262646453608586\n",
            "\tF1 score = 0.6280960614423612\n",
            "Adam: The Training Resulting Epoch : 54:\n",
            "\tAverage Loss = 1.27941470981902\n",
            "\tAccuracy = 0.8512930245272573\n",
            "\tAverage Precision = 0.6289651113151956\n",
            "\tAverage Recall = 0.6253936360495879\n",
            "\tF1 score = 0.6271742892376109\n",
            "Rprop: The Training Resulting Epoch : 55:\n",
            "\tAverage Loss = 1.2774704882016914\n",
            "\tAccuracy = 0.8525763513154435\n",
            "\tAverage Precision = 0.6321262213273923\n",
            "\tAverage Recall = 0.6288440680426134\n",
            "\tF1 score = 0.630480873160814\n",
            "Adam: The Training Resulting Epoch : 55:\n",
            "\tAverage Loss = 1.2784020761672106\n",
            "\tAccuracy = 0.8520723705849977\n",
            "\tAverage Precision = 0.6308770585630583\n",
            "\tAverage Recall = 0.6275199426155895\n",
            "\tF1 score = 0.6291940225798109\n",
            "Rprop: The Training Resulting Epoch : 56:\n",
            "\tAverage Loss = 1.2764376315953163\n",
            "\tAccuracy = 0.8527902038401901\n",
            "\tAverage Precision = 0.632786121845976\n",
            "\tAverage Recall = 0.628926582460878\n",
            "\tF1 score = 0.6308504490487764\n",
            "Adam: The Training Resulting Epoch : 56:\n",
            "\tAverage Loss = 1.2775244898002285\n",
            "\tAccuracy = 0.8528756676189896\n",
            "\tAverage Precision = 0.6328995231625665\n",
            "\tAverage Recall = 0.629519236734393\n",
            "\tF1 score = 0.6312048543755481\n",
            "Rprop: The Training Resulting Epoch : 57:\n",
            "\tAverage Loss = 1.2754982076803656\n",
            "\tAccuracy = 0.8533088057449976\n",
            "\tAverage Precision = 0.6339529491049741\n",
            "\tAverage Recall = 0.6307337092089234\n",
            "\tF1 score = 0.6323392318948166\n",
            "Adam: The Training Resulting Epoch : 57:\n",
            "\tAverage Loss = 1.2766415821988866\n",
            "\tAccuracy = 0.852189753991252\n",
            "\tAverage Precision = 0.6311436818009603\n",
            "\tAverage Recall = 0.6279151127381736\n",
            "\tF1 score = 0.6295252578051359\n",
            "Rprop: The Training Resulting Epoch : 58:\n",
            "\tAverage Loss = 1.2746110545233293\n",
            "\tAccuracy = 0.8546899429964308\n",
            "\tAverage Precision = 0.6373375238324611\n",
            "\tAverage Recall = 0.634487802061003\n",
            "\tF1 score = 0.6359094703250688\n",
            "Adam: The Training Resulting Epoch : 58:\n",
            "\tAverage Loss = 1.2757060351013998\n",
            "\tAccuracy = 0.8527740413819678\n",
            "\tAverage Precision = 0.632566789920786\n",
            "\tAverage Recall = 0.6295542874958704\n",
            "\tF1 score = 0.6310569435022017\n",
            "Rprop: The Training Resulting Epoch : 59:\n",
            "\tAverage Loss = 1.273740204948613\n",
            "\tAccuracy = 0.8540419683473607\n",
            "\tAverage Precision = 0.6357086822249264\n",
            "\tAverage Recall = 0.6328764393830316\n",
            "\tF1 score = 0.6342893991716302\n",
            "Adam: The Training Resulting Epoch : 59:\n",
            "\tAverage Loss = 1.274743889728157\n",
            "\tAccuracy = 0.8518643063191065\n",
            "\tAverage Precision = 0.6302711574996889\n",
            "\tAverage Recall = 0.6273185205695432\n",
            "\tF1 score = 0.6287913728544329\n",
            "Rprop: The Training Resulting Epoch : 60:\n",
            "\tAverage Loss = 1.2728032554300002\n",
            "\tAccuracy = 0.8546067980758362\n",
            "\tAverage Precision = 0.6370493270705777\n",
            "\tAverage Recall = 0.6345764093130661\n",
            "\tF1 score = 0.6358104636626981\n",
            "Adam: The Training Resulting Epoch : 60:\n",
            "\tAverage Loss = 1.2739422406568897\n",
            "\tAccuracy = 0.8546155894083941\n",
            "\tAverage Precision = 0.6371783189703378\n",
            "\tAverage Recall = 0.6342123868058605\n",
            "\tF1 score = 0.6356918933875836\n",
            "Rprop: The Training Resulting Epoch : 61:\n",
            "\tAverage Loss = 1.2720386441818854\n",
            "\tAccuracy = 0.8546250079044205\n",
            "\tAverage Precision = 0.6371900126087382\n",
            "\tAverage Recall = 0.6342766348326675\n",
            "\tF1 score = 0.6357299859335563\n",
            "Adam: The Training Resulting Epoch : 61:\n",
            "\tAverage Loss = 1.2731101092951238\n",
            "\tAccuracy = 0.855187532909753\n",
            "\tAverage Precision = 0.638513996407539\n",
            "\tAverage Recall = 0.6359971388972063\n",
            "\tF1 score = 0.6372530825537526\n",
            "Rprop: The Training Resulting Epoch : 62:\n",
            "\tAverage Loss = 1.271237517087988\n",
            "\tAccuracy = 0.8554095331309787\n",
            "\tAverage Precision = 0.6391651111023113\n",
            "\tAverage Recall = 0.636223443236006\n",
            "\tF1 score = 0.6376908847089525\n",
            "Adam: The Training Resulting Epoch : 62:\n",
            "\tAverage Loss = 1.2722948793789146\n",
            "\tAccuracy = 0.8545189076566483\n",
            "\tAverage Precision = 0.636898986854485\n",
            "\tAverage Recall = 0.6340973602798045\n",
            "\tF1 score = 0.6354950857882216\n",
            "Rprop: The Training Resulting Epoch : 63:\n",
            "\tAverage Loss = 1.2704326899641425\n",
            "\tAccuracy = 0.8542181740212674\n",
            "\tAverage Precision = 0.636140979052485\n",
            "\tAverage Recall = 0.6333582982633641\n",
            "\tF1 score = 0.634746588907321\n",
            "Adam: The Training Resulting Epoch : 63:\n",
            "\tAverage Loss = 1.27159079703189\n",
            "\tAccuracy = 0.8549850601920084\n",
            "\tAverage Precision = 0.6380415509637728\n",
            "\tAverage Recall = 0.635356339082119\n",
            "\tF1 score = 0.6366961138721697\n",
            "Rprop: The Training Resulting Epoch : 64:\n",
            "\tAverage Loss = 1.269642011781091\n",
            "\tAccuracy = 0.8540568012379653\n",
            "\tAverage Precision = 0.6356905883692681\n",
            "\tAverage Recall = 0.6331149458650736\n",
            "\tF1 score = 0.6344001528732499\n",
            "Adam: The Training Resulting Epoch : 64:\n",
            "\tAverage Loss = 1.2709368444970457\n",
            "\tAccuracy = 0.8546603199759996\n",
            "\tAverage Precision = 0.6372291060551633\n",
            "\tAverage Recall = 0.6345496664184679\n",
            "\tF1 score = 0.6358865636559855\n",
            "Rprop: The Training Resulting Epoch : 65:\n",
            "\tAverage Loss = 1.2689155612713008\n",
            "\tAccuracy = 0.8545731235738836\n",
            "\tAverage Precision = 0.637046091271001\n",
            "\tAverage Recall = 0.6341883355827388\n",
            "\tF1 score = 0.6356140012862131\n",
            "Adam: The Training Resulting Epoch : 65:\n",
            "\tAverage Loss = 1.2701722863550622\n",
            "\tAccuracy = 0.854811668720429\n",
            "\tAverage Precision = 0.6375097220773939\n",
            "\tAverage Recall = 0.6352828326632075\n",
            "\tF1 score = 0.636394329277328\n",
            "Rprop: The Training Resulting Epoch : 66:\n",
            "\tAverage Loss = 1.2683080842179122\n",
            "\tAccuracy = 0.855461638181825\n",
            "\tAverage Precision = 0.6392405949934074\n",
            "\tAverage Recall = 0.6365474724415567\n",
            "\tF1 score = 0.6378911911963516\n",
            "Adam: The Training Resulting Epoch : 66:\n",
            "\tAverage Loss = 1.269578179259373\n",
            "\tAccuracy = 0.8559774781275802\n",
            "\tAverage Precision = 0.6405360683564506\n",
            "\tAverage Recall = 0.6378384834122831\n",
            "\tF1 score = 0.6391844297057876\n",
            "Rprop: The Training Resulting Epoch : 67:\n",
            "\tAverage Loss = 1.2676999761798318\n",
            "\tAccuracy = 0.856641417549529\n",
            "\tAverage Precision = 0.6420563898402248\n",
            "\tAverage Recall = 0.6400032890691824\n",
            "\tF1 score = 0.6410281955285879\n",
            "Adam: The Training Resulting Epoch : 67:\n",
            "\tAverage Loss = 1.2687955069653734\n",
            "\tAccuracy = 0.8556054627221447\n",
            "\tAverage Precision = 0.6394296563595756\n",
            "\tAverage Recall = 0.6375221681680946\n",
            "\tF1 score = 0.6384744875776681\n",
            "Rprop: The Training Resulting Epoch : 68:\n",
            "\tAverage Loss = 1.266975781492723\n",
            "\tAccuracy = 0.855122181926821\n",
            "\tAverage Precision = 0.638367499121737\n",
            "\tAverage Recall = 0.6357757317122235\n",
            "\tF1 score = 0.6370689794267154\n",
            "Adam: The Training Resulting Epoch : 68:\n",
            "\tAverage Loss = 1.2681950280423182\n",
            "\tAccuracy = 0.8553768157020116\n",
            "\tAverage Precision = 0.6388733833118077\n",
            "\tAverage Recall = 0.6368903396224606\n",
            "\tF1 score = 0.6378803202482536\n",
            "Rprop: The Training Resulting Epoch : 69:\n",
            "\tAverage Loss = 1.2663502072673052\n",
            "\tAccuracy = 0.8563846406319684\n",
            "\tAverage Precision = 0.6414295376585786\n",
            "\tAverage Recall = 0.6393053381332513\n",
            "\tF1 score = 0.640365676319921\n",
            "Adam: The Training Resulting Epoch : 69:\n",
            "\tAverage Loss = 1.26747493769052\n",
            "\tAccuracy = 0.855752927257047\n",
            "\tAverage Precision = 0.6398452732646525\n",
            "\tAverage Recall = 0.637726303368839\n",
            "\tF1 score = 0.6387840310635704\n",
            "Rprop: The Training Resulting Epoch : 70:\n",
            "\tAverage Loss = 1.265732504348822\n",
            "\tAccuracy = 0.8569003388634696\n",
            "\tAverage Precision = 0.6427321780693526\n",
            "\tAverage Recall = 0.6405651810253647\n",
            "\tF1 score = 0.6416468499339197\n",
            "Adam: The Training Resulting Epoch : 70:\n",
            "\tAverage Loss = 1.266905803263956\n",
            "\tAccuracy = 0.8560135919140522\n",
            "\tAverage Precision = 0.6404777277612663\n",
            "\tAverage Recall = 0.6384543283117742\n",
            "\tF1 score = 0.6394644274255602\n",
            "Rprop: The Training Resulting Epoch : 71:\n",
            "\tAverage Loss = 1.2651402695237681\n",
            "\tAccuracy = 0.8572947193413079\n",
            "\tAverage Precision = 0.6437657859372735\n",
            "\tAverage Recall = 0.6413992858796025\n",
            "\tF1 score = 0.64258035707451\n",
            "Adam: The Training Resulting Epoch : 71:\n",
            "\tAverage Loss = 1.2662319111237073\n",
            "\tAccuracy = 0.8572522206181598\n",
            "\tAverage Precision = 0.6435248296659268\n",
            "\tAverage Recall = 0.641754118644445\n",
            "\tF1 score = 0.6426382544131501\n",
            "Rprop: The Training Resulting Epoch : 72:\n",
            "\tAverage Loss = 1.2644326061464557\n",
            "\tAccuracy = 0.85622884318035\n",
            "\tAverage Precision = 0.6410853896433261\n",
            "\tAverage Recall = 0.6387515812368008\n",
            "\tF1 score = 0.6399163575668255\n",
            "Adam: The Training Resulting Epoch : 72:\n",
            "\tAverage Loss = 1.2656184664784396\n",
            "\tAccuracy = 0.8575413513318364\n",
            "\tAverage Precision = 0.6443058627361643\n",
            "\tAverage Recall = 0.6422868905174259\n",
            "\tF1 score = 0.6432947925012784\n",
            "Rprop: The Training Resulting Epoch : 73:\n",
            "\tAverage Loss = 1.2639417740552394\n",
            "\tAccuracy = 0.8577282306484523\n",
            "\tAverage Precision = 0.6447467209029544\n",
            "\tAverage Recall = 0.6428486553816967\n",
            "\tF1 score = 0.6437962891575243\n",
            "Adam: The Training Resulting Epoch : 73:\n",
            "\tAverage Loss = 1.2650584927896542\n",
            "\tAccuracy = 0.8567103182369854\n",
            "\tAverage Precision = 0.6421269009246361\n",
            "\tAverage Recall = 0.6405395617157934\n",
            "\tF1 score = 0.641332249129662\n",
            "Rprop: The Training Resulting Epoch : 74:\n",
            "\tAverage Loss = 1.2633374630356728\n",
            "\tAccuracy = 0.8565847899441091\n",
            "\tAverage Precision = 0.641936409258077\n",
            "\tAverage Recall = 0.6397916411994514\n",
            "\tF1 score = 0.6408622307646329\n",
            "Adam: The Training Resulting Epoch : 74:\n",
            "\tAverage Loss = 1.2644486623660063\n",
            "\tAccuracy = 0.8573145579534815\n",
            "\tAverage Precision = 0.6437093978276007\n",
            "\tAverage Recall = 0.6418146111620893\n",
            "\tF1 score = 0.6427606080928787\n",
            "Rprop: The Training Resulting Epoch : 75:\n",
            "\tAverage Loss = 1.262740381158111\n",
            "\tAccuracy = 0.8579431239650712\n",
            "\tAverage Precision = 0.6453396499783175\n",
            "\tAverage Recall = 0.6432030279756722\n",
            "\tF1 score = 0.6442695675364131\n",
            "Adam: The Training Resulting Epoch : 75:\n",
            "\tAverage Loss = 1.263928668649926\n",
            "\tAccuracy = 0.8571566922400111\n",
            "\tAverage Precision = 0.6432828382136402\n",
            "\tAverage Recall = 0.6415297986593034\n",
            "\tF1 score = 0.6424051224847855\n",
            "Rprop: The Training Resulting Epoch : 76:\n",
            "\tAverage Loss = 1.2622016306359491\n",
            "\tAccuracy = 0.8580132940601936\n",
            "\tAverage Precision = 0.6455321899779047\n",
            "\tAverage Recall = 0.6433193851695274\n",
            "\tF1 score = 0.6444238880124266\n",
            "Adam: The Training Resulting Epoch : 76:\n",
            "\tAverage Loss = 1.2633927283505062\n",
            "\tAccuracy = 0.8577216505589649\n",
            "\tAverage Precision = 0.6446844927939704\n",
            "\tAverage Recall = 0.6429902801961022\n",
            "\tF1 score = 0.6438362719448459\n",
            "Rprop: The Training Resulting Epoch : 77:\n",
            "\tAverage Loss = 1.2615899372352386\n",
            "\tAccuracy = 0.8580290125602184\n",
            "\tAverage Precision = 0.6455980359778356\n",
            "\tAverage Recall = 0.6432632979625571\n",
            "\tF1 score = 0.6444285523122978\n",
            "Adam: The Training Resulting Epoch : 77:\n",
            "\tAverage Loss = 1.26282802388369\n",
            "\tAccuracy = 0.8584786035177582\n",
            "\tAverage Precision = 0.6465564609525916\n",
            "\tAverage Recall = 0.6449677644719818\n",
            "\tF1 score = 0.6457611355891101\n",
            "Rprop: The Training Resulting Epoch : 78:\n",
            "\tAverage Loss = 1.2611254629747808\n",
            "\tAccuracy = 0.8582954585368814\n",
            "\tAverage Precision = 0.6461505291004898\n",
            "\tAverage Recall = 0.644328444499267\n",
            "\tF1 score = 0.6452382004587748\n",
            "Adam: The Training Resulting Epoch : 78:\n",
            "\tAverage Loss = 1.2622550668638168\n",
            "\tAccuracy = 0.858427706001357\n",
            "\tAverage Precision = 0.6465075297373315\n",
            "\tAverage Recall = 0.6445746601654727\n",
            "\tF1 score = 0.6455396481090511\n",
            "Rprop: The Training Resulting Epoch : 79:\n",
            "\tAverage Loss = 1.2605585383222921\n",
            "\tAccuracy = 0.8589886171552678\n",
            "\tAverage Precision = 0.6478195133861351\n",
            "\tAverage Recall = 0.6462922295041762\n",
            "\tF1 score = 0.6470549702107495\n",
            "Adam: The Training Resulting Epoch : 79:\n",
            "\tAverage Loss = 1.2617816375819628\n",
            "\tAccuracy = 0.8587872009987297\n",
            "\tAverage Precision = 0.6473813057724356\n",
            "\tAverage Recall = 0.6455655539639158\n",
            "\tF1 score = 0.6464721548913251\n",
            "Rprop: The Training Resulting Epoch : 80:\n",
            "\tAverage Loss = 1.2600699953848424\n",
            "\tAccuracy = 0.8594040720610903\n",
            "\tAverage Precision = 0.6488192187197704\n",
            "\tAverage Recall = 0.6474692110487378\n",
            "\tF1 score = 0.6481435119077136\n",
            "Adam: The Training Resulting Epoch : 80:\n",
            "\tAverage Loss = 1.2612771223466255\n",
            "\tAccuracy = 0.8585966164131447\n",
            "\tAverage Precision = 0.6468335576097951\n",
            "\tAverage Recall = 0.6453260857832483\n",
            "\tF1 score = 0.6460789423658138\n",
            "Rprop: The Training Resulting Epoch : 81:\n",
            "\tAverage Loss = 1.2596772334779693\n",
            "\tAccuracy = 0.8586587971933254\n",
            "\tAverage Precision = 0.6469562876045577\n",
            "\tAverage Recall = 0.645596415397479\n",
            "\tF1 score = 0.6462756361520754\n",
            "Adam: The Training Resulting Epoch : 81:\n",
            "\tAverage Loss = 1.2608253249389765\n",
            "\tAccuracy = 0.858977949948337\n",
            "\tAverage Precision = 0.6478566980815963\n",
            "\tAverage Recall = 0.6460557454820668\n",
            "\tF1 score = 0.6469549684395819\n",
            "Rprop: The Training Resulting Epoch : 82:\n",
            "\tAverage Loss = 1.2591863652606083\n",
            "\tAccuracy = 0.8594829718292446\n",
            "\tAverage Precision = 0.649101106860495\n",
            "\tAverage Recall = 0.6473894636414486\n",
            "\tF1 score = 0.6482441553844784\n",
            "Adam: The Training Resulting Epoch : 82:\n",
            "\tAverage Loss = 1.260363754885138\n",
            "\tAccuracy = 0.857245879396493\n",
            "\tAverage Precision = 0.6434418178629103\n",
            "\tAverage Recall = 0.6419773444663558\n",
            "\tF1 score = 0.6427087469300145\n",
            "Rprop: The Training Resulting Epoch : 83:\n",
            "\tAverage Loss = 1.2587784115063487\n",
            "\tAccuracy = 0.8590368026703058\n",
            "\tAverage Precision = 0.6479228384154659\n",
            "\tAverage Recall = 0.6464743389173008\n",
            "\tF1 score = 0.6471977781922751\n",
            "Adam: The Training Resulting Epoch : 83:\n",
            "\tAverage Loss = 1.2599170276456253\n",
            "\tAccuracy = 0.8579361819415678\n",
            "\tAverage Precision = 0.6451800019402124\n",
            "\tAverage Recall = 0.6436717494013116\n",
            "\tF1 score = 0.6444249931698387\n",
            "Rprop: The Training Resulting Epoch : 84:\n",
            "\tAverage Loss = 1.2584140273498903\n",
            "\tAccuracy = 0.8598213676731521\n",
            "\tAverage Precision = 0.6499135108752296\n",
            "\tAverage Recall = 0.6483521024059231\n",
            "\tF1 score = 0.6491318676969646\n",
            "Adam: The Training Resulting Epoch : 84:\n",
            "\tAverage Loss = 1.2595199825196306\n",
            "\tAccuracy = 0.8584307626870193\n",
            "\tAverage Precision = 0.6464146946117026\n",
            "\tAverage Recall = 0.6449238445552514\n",
            "\tF1 score = 0.6456684089904476\n",
            "Rprop: The Training Resulting Epoch : 85:\n",
            "\tAverage Loss = 1.2580077571298705\n",
            "\tAccuracy = 0.8593452462960698\n",
            "\tAverage Precision = 0.6486805570971389\n",
            "\tAverage Recall = 0.6472939724411462\n",
            "\tF1 score = 0.6479865230041756\n",
            "Adam: The Training Resulting Epoch : 85:\n",
            "\tAverage Loss = 1.2591500124366732\n",
            "\tAccuracy = 0.8597104530935481\n",
            "\tAverage Precision = 0.649606330532799\n",
            "\tAverage Recall = 0.648171142739435\n",
            "\tF1 score = 0.6488879430624711\n",
            "Rprop: The Training Resulting Epoch : 86:\n",
            "\tAverage Loss = 1.2575329815377105\n",
            "\tAccuracy = 0.8599721764816942\n",
            "\tAverage Precision = 0.650251458323683\n",
            "\tAverage Recall = 0.648863285397244\n",
            "\tF1 score = 0.6495566301923072\n",
            "Adam: The Training Resulting Epoch : 86:\n",
            "\tAverage Loss = 1.2586514151809085\n",
            "\tAccuracy = 0.860035559518392\n",
            "\tAverage Precision = 0.650351783962553\n",
            "\tAverage Recall = 0.6492099936819902\n",
            "\tF1 score = 0.6497803872358648\n",
            "Rprop: The Training Resulting Epoch : 87:\n",
            "\tAverage Loss = 1.2571840250617874\n",
            "\tAccuracy = 0.8588755854504319\n",
            "\tAverage Precision = 0.6475331952363115\n",
            "\tAverage Recall = 0.6460200195876145\n",
            "\tF1 score = 0.6467757223689212\n",
            "Adam: The Training Resulting Epoch : 87:\n",
            "\tAverage Loss = 1.258403938861972\n",
            "\tAccuracy = 0.8596730788863112\n",
            "\tAverage Precision = 0.6495170348315779\n",
            "\tAverage Recall = 0.6480618915819436\n",
            "\tF1 score = 0.648788647286498\n",
            "Rprop: The Training Resulting Epoch : 88:\n",
            "\tAverage Loss = 1.2568005949503371\n",
            "\tAccuracy = 0.8607645222843686\n",
            "\tAverage Precision = 0.6522467886651687\n",
            "\tAverage Recall = 0.6508063487726498\n",
            "\tF1 score = 0.6515257725629336\n",
            "Adam: The Training Resulting Epoch : 88:\n",
            "\tAverage Loss = 1.2579991724538635\n",
            "\tAccuracy = 0.8590763889231403\n",
            "\tAverage Precision = 0.6479785224100341\n",
            "\tAverage Recall = 0.6467193787292856\n",
            "\tF1 score = 0.6473483382867452\n",
            "Rprop: The Training Resulting Epoch : 89:\n",
            "\tAverage Loss = 1.2564322994574293\n",
            "\tAccuracy = 0.8588279473284947\n",
            "\tAverage Precision = 0.6473064022029451\n",
            "\tAverage Recall = 0.646266702719432\n",
            "\tF1 score = 0.6467861346359369\n",
            "Adam: The Training Resulting Epoch : 89:\n",
            "\tAverage Loss = 1.2575663040978409\n",
            "\tAccuracy = 0.8596838635530013\n",
            "\tAverage Precision = 0.6495061813474722\n",
            "\tAverage Recall = 0.6482163200201101\n",
            "\tF1 score = 0.6488606096599042\n",
            "Rprop: The Training Resulting Epoch : 90:\n",
            "\tAverage Loss = 1.256041002581016\n",
            "\tAccuracy = 0.8605800244024991\n",
            "\tAverage Precision = 0.651752785129421\n",
            "\tAverage Recall = 0.6504521859080427\n",
            "\tF1 score = 0.6511018360210059\n",
            "Adam: The Training Resulting Epoch : 90:\n",
            "\tAverage Loss = 1.2570891136441114\n",
            "\tAccuracy = 0.86047939875857\n",
            "\tAverage Precision = 0.6514267178486226\n",
            "\tAverage Recall = 0.6504457785594444\n",
            "\tF1 score = 0.6509358786433078\n",
            "Rprop: The Training Resulting Epoch : 91:\n",
            "\tAverage Loss = 1.2557096977446311\n",
            "\tAccuracy = 0.8604606697682\n",
            "\tAverage Precision = 0.6514915354918652\n",
            "\tAverage Recall = 0.6500300491334406\n",
            "\tF1 score = 0.6507599717567739\n",
            "Adam: The Training Resulting Epoch : 91:\n",
            "\tAverage Loss = 1.2568508065878856\n",
            "\tAccuracy = 0.858952267367173\n",
            "\tAverage Precision = 0.647705851582978\n",
            "\tAverage Recall = 0.6462785313612105\n",
            "\tF1 score = 0.6469914042744116\n",
            "Rprop: The Training Resulting Epoch : 92:\n",
            "\tAverage Loss = 1.2552828138207215\n",
            "\tAccuracy = 0.8585000430664158\n",
            "\tAverage Precision = 0.64657064395338\n",
            "\tAverage Recall = 0.6451594649694168\n",
            "\tF1 score = 0.6458642836246303\n",
            "Adam: The Training Resulting Epoch : 92:\n",
            "\tAverage Loss = 1.2564417089555076\n",
            "\tAccuracy = 0.8590076908373077\n",
            "\tAverage Precision = 0.6477863807294574\n",
            "\tAverage Recall = 0.6466125479942284\n",
            "\tF1 score = 0.6471989321135307\n",
            "Rprop: The Training Resulting Epoch : 93:\n",
            "\tAverage Loss = 1.2549815677534375\n",
            "\tAccuracy = 0.8609785940153555\n",
            "\tAverage Precision = 0.6526760969902894\n",
            "\tAverage Recall = 0.6516945848849078\n",
            "\tF1 score = 0.6521849716537645\n",
            "Adam: The Training Resulting Epoch : 93:\n",
            "\tAverage Loss = 1.256196695992424\n",
            "\tAccuracy = 0.8598315123538273\n",
            "\tAverage Precision = 0.6497623485753159\n",
            "\tAverage Recall = 0.6489667213511598\n",
            "\tF1 score = 0.6493642912547176\n",
            "Rprop: The Training Resulting Epoch : 94:\n",
            "\tAverage Loss = 1.2547446557813065\n",
            "\tAccuracy = 0.8606676681681535\n",
            "\tAverage Precision = 0.6518677632922307\n",
            "\tAverage Recall = 0.6510140606363573\n",
            "\tF1 score = 0.6514406322734536\n",
            "Adam: The Training Resulting Epoch : 94:\n",
            "\tAverage Loss = 1.2558074309845462\n",
            "\tAccuracy = 0.8620366743309664\n",
            "\tAverage Precision = 0.6553041473132364\n",
            "\tAverage Recall = 0.6544069781485895\n",
            "\tF1 score = 0.6548552554446365\n",
            "Rprop: The Training Resulting Epoch : 95:\n",
            "\tAverage Loss = 1.2542865802506629\n",
            "\tAccuracy = 0.8616022772622801\n",
            "\tAverage Precision = 0.6542882547325379\n",
            "\tAverage Recall = 0.653096829691736\n",
            "\tF1 score = 0.6536919993370328\n",
            "Adam: The Training Resulting Epoch : 95:\n",
            "\tAverage Loss = 1.25548009003173\n",
            "\tAccuracy = 0.8599187748493576\n",
            "\tAverage Precision = 0.6500546288024991\n",
            "\tAverage Recall = 0.648937978103241\n",
            "\tF1 score = 0.649495823500645\n",
            "Rprop: The Training Resulting Epoch : 96:\n",
            "\tAverage Loss = 1.254041888439921\n",
            "\tAccuracy = 0.8607799579456362\n",
            "\tAverage Precision = 0.6522113973908572\n",
            "\tAverage Recall = 0.6510912034096158\n",
            "\tF1 score = 0.6516508189945542\n",
            "Adam: The Training Resulting Epoch : 96:\n",
            "\tAverage Loss = 1.255271805129325\n",
            "\tAccuracy = 0.8603405085386892\n",
            "\tAverage Precision = 0.6511085155693369\n",
            "\tAverage Recall = 0.6499985765181062\n",
            "\tF1 score = 0.6505530726143226\n",
            "Rprop: The Training Resulting Epoch : 97:\n",
            "\tAverage Loss = 1.253764532864583\n",
            "\tAccuracy = 0.8608237532505458\n",
            "\tAverage Precision = 0.6523678736780193\n",
            "\tAverage Recall = 0.6510437298242088\n",
            "\tF1 score = 0.6517051291481769\n",
            "Adam: The Training Resulting Epoch : 97:\n",
            "\tAverage Loss = 1.2548101863016976\n",
            "\tAccuracy = 0.8595100211471657\n",
            "\tAverage Precision = 0.6489455187264181\n",
            "\tAverage Recall = 0.6482039794363701\n",
            "\tF1 score = 0.6485745371241296\n",
            "Rprop: The Training Resulting Epoch : 98:\n",
            "\tAverage Loss = 1.2534671796863552\n",
            "\tAccuracy = 0.8612394621446771\n",
            "\tAverage Precision = 0.6534461406699913\n",
            "\tAverage Recall = 0.651969229133721\n",
            "\tF1 score = 0.6527068494330328\n",
            "Adam: The Training Resulting Epoch : 98:\n",
            "\tAverage Loss = 1.2545526801212172\n",
            "\tAccuracy = 0.8609988485341619\n",
            "\tAverage Precision = 0.6527707504166873\n",
            "\tAverage Recall = 0.6516007540016521\n",
            "\tF1 score = 0.6521852274769111\n",
            "Rprop: The Training Resulting Epoch : 99:\n",
            "\tAverage Loss = 1.2532421574782655\n",
            "\tAccuracy = 0.8610719363846981\n",
            "\tAverage Precision = 0.6529229289428957\n",
            "\tAverage Recall = 0.6518847248998909\n",
            "\tF1 score = 0.6524034138844098\n",
            "Adam: The Training Resulting Epoch : 99:\n",
            "\tAverage Loss = 1.254293970388097\n",
            "\tAccuracy = 0.8606629523077642\n",
            "\tAverage Precision = 0.651916688105079\n",
            "\tAverage Recall = 0.6508041806588173\n",
            "\tF1 score = 0.6513599593481755\n",
            "Rprop: The Training Resulting Epoch : 100:\n",
            "\tAverage Loss = 1.25283792869986\n",
            "\tAccuracy = 0.8608145114113308\n",
            "\tAverage Precision = 0.652272698783743\n",
            "\tAverage Recall = 0.6512605023480246\n",
            "\tF1 score = 0.6517662075794899\n",
            "Adam: The Training Resulting Epoch : 100:\n",
            "\tAverage Loss = 1.2540163951210792\n",
            "\tAccuracy = 0.8611108133663287\n",
            "\tAverage Precision = 0.6529943022094808\n",
            "\tAverage Recall = 0.65206696967074\n",
            "\tF1 score = 0.6525303064744923\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcWeFgsQbNRl",
        "colab_type": "code",
        "outputId": "cbe57c68-fe6c-4789-d54e-c85aa74dc88b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "num_epochs = range(epochs)\n",
        "plt.plot(num_epochs, accuracies, 'oc-', label='Accuracy')\n",
        "plt.plot(num_epochs, acc_adam, 'oc-', label='Accuracy', color='red')\n",
        "plt.xlabel('Number of Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niEhGShAiIpLR/wd/R9I2NfXpaAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRNI1VSb83Hz",
        "colab_type": "code",
        "outputId": "66254797-7909-4bc1-e53b-fa5392ad2cc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "#Block to obtain test loss\n",
        "optimizer = Rprop(model.parameters(), lr=1e-5)\n",
        "optimizer_ = Adam(model.parameters(), lr=1e-5)\n",
        "inputs = torch.from_numpy(x_train_np).cuda().float()\n",
        "outputs = torch.from_numpy(y_train_np).cuda().float()\n",
        "print(inputs.size())\n",
        "print(outputs.size())\n",
        "tensor = TensorDataset(inputs, outputs)\n",
        "loader = DataLoader(tensor, batch_size, shuffle=True, drop_last=True)\n",
        "avg_loss, avg_accu, avg_prec, avg_rec = model_loss(model, loader, train=True, optimizer=optimizer)\n",
        "av_loss, av_accu, av_prec, av_rec = model_loss(model, loader, train=True, optimizer=optimizer_)\n",
        "f1 = (2*(avg_prec*avg_rec)/(avg_rec + avg_prec))\n",
        "f1_adam = (2*(av_prec*av_rec)/(av_rec + av_prec))\n",
        "print(\"Rprop: The Testing Resulting Average Loss = \" + str(avg_loss) + \"\\n\\tAccuracy = \" + str(avg_accu) + \"\\n\\tAverage Precision = \" + str(avg_prec) + \"\\n\\tAverage Recall = \" + str(avg_rec) +  \"\\n\\tF1 score = \" + str(f1))\n",
        "print(\"Adam: The Testing Resulting Average Loss = \" + str(avg_loss) +\"\\n\\tAccuracy = \" + str(av_accu) + \"\\n\\tAverage Precision = \" + str(av_prec) + \"\\n\\tAverage Recall = \" + str(av_rec) +  \"\\n\\tF1 score = \" + str(f1_adam))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([109242, 1000])\n",
            "torch.Size([109242, 5])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:51: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Rprop: The Testing Resulting Average Loss = 1.2526276099025015\n",
            "\tAccuracy = 0.8615079637285951\n",
            "\tAverage Precision = 0.6540547556887216\n",
            "\tAverage Recall = 0.6528466956564315\n",
            "\tF1 score = 0.6534501673255643\n",
            "Adam: The Testing Resulting Average Loss = 1.2526276099025015\n",
            "\tAccuracy = 0.8612695682431466\n",
            "\tAverage Precision = 0.653416301955576\n",
            "\tAverage Recall = 0.6523842536422375\n",
            "\tF1 score = 0.6528998699557194\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjK9hQB8-xZ6",
        "colab_type": "code",
        "outputId": "aafea939-f67e-46e8-c5a8-3e855fc583df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "#code to load the trained model\n",
        "model.load_state_dict(torch.load('/content/drive/My Drive/110534_sentiment_analysis.pth'))\n",
        "model.eval()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CnnRegressor(\n",
              "  (input_layer): Conv1d(1000, 64, kernel_size=(1,), stride=(1,))\n",
              "  (max_pooling_layer): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv_layer): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
              "  (max_pooling_1): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv_layer_1): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
              "  (flatten_layer): Flatten()\n",
              "  (linear_layer): Linear(in_features=256, out_features=64, bias=True)\n",
              "  (output_layer): Linear(in_features=64, out_features=5, bias=True)\n",
              "  (softmax): Softmax(dim=None)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    }
  ]
}